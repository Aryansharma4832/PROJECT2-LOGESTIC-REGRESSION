{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Project 2 </h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform logistic regression using the following data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the feature sets given below to construct a logistic regression model \n",
    " 'ed', 'employ', 'equip',   'callcard', 'wireless'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CASE 1:- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (160, 5) (160,)\n",
      "Test set: (40, 5) (40,)\n",
      "[[18  7]\n",
      " [ 9  6]]\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "#start here \n",
    "#remember to use different code blocks for different segments \n",
    "\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df=pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%203/data/ChurnData.csv\")\n",
    "#display(df)\n",
    "\n",
    "dff = df[[\"ed\",\"employ\",\"equip\",\"callcard\",\"wireless\"]]\n",
    "dff.head()\n",
    "\n",
    "X = np.asanyarray(dff[[\"ed\",\"employ\",\"equip\",\"callcard\",\"wireless\"]])\n",
    "\n",
    "y = np.asanyarray(df[\"churn\"])\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test , y_train , y_test = train_test_split(X,y,test_size = 0.2, random_state = 4)\n",
    "\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "LR = LogisticRegression(C = 0.01 , solver = 'liblinear').fit(X_train,y_train)\n",
    "LR\n",
    "\n",
    "yhat = LR.predict(X_test)\n",
    "yhat\n",
    "\n",
    "yhat_prob = LR.predict_proba(X_test)\n",
    "yhat_prob\n",
    "\n",
    "a = confusion_matrix(y_test , yhat)\n",
    "print(a)\n",
    "print((a[0][0]+a[1][1])/(a[0][0]+a[0][1]+a[1][0]+a[1][1]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# please remember to train and test your model according to the feature set selected \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "case 2 :- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (160, 5) (160,)\n",
      "Test set: (40, 5) (40,)\n",
      "[[23  2]\n",
      " [ 8  7]]\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "## now trying to get higher accuracy with different featured sets:-\n",
    "\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df=pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%203/data/ChurnData.csv\")\n",
    "\n",
    "\n",
    "dff = df[[\"ed\",\"employ\",\"equip\",\"logtoll\",\"loglong\"]]\n",
    "dff.head()\n",
    "\n",
    "X = np.asanyarray(dff[[\"ed\",\"employ\",\"equip\",\"logtoll\",\"loglong\"]])\n",
    "\n",
    "y = np.asanyarray(df[\"churn\"])\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test , y_train , y_test = train_test_split(X,y,test_size = 0.2, random_state = 4)\n",
    "\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "LR = LogisticRegression(C = 0.01 , solver = 'liblinear').fit(X_train,y_train)\n",
    "LR\n",
    "\n",
    "yhat = LR.predict(X_test)\n",
    "yhat\n",
    "\n",
    "yhat_prob = LR.predict_proba(X_test)\n",
    "yhat_prob\n",
    "\n",
    "a = confusion_matrix(y_test , yhat)\n",
    "print(a)\n",
    "print((a[0][0]+a[1][1])/(a[0][0]+a[0][1]+a[1][0]+a[1][1]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CASE 3 :- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (160, 5) (160,)\n",
      "Test set: (40, 5) (40,)\n",
      "[[23  2]\n",
      " [ 7  8]]\n",
      "0.775\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df=pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%203/data/ChurnData.csv\")\n",
    "\n",
    "\n",
    "dff = df[[\"age\",\"employ\",\"longmon\",\"logtoll\",\"loglong\"]]\n",
    "dff.head()\n",
    "\n",
    "X = np.asanyarray(dff[[\"age\",\"employ\",\"longmon\",\"logtoll\",\"loglong\"]])\n",
    "\n",
    "y = np.asanyarray(df[\"churn\"])\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test , y_train , y_test = train_test_split(X,y,test_size = 0.2, random_state = 4)\n",
    "\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "LR = LogisticRegression(C = 0.01 , solver = 'liblinear').fit(X_train,y_train)\n",
    "LR\n",
    "\n",
    "yhat = LR.predict(X_test)\n",
    "yhat\n",
    "\n",
    "yhat_prob = LR.predict_proba(X_test)\n",
    "yhat_prob\n",
    "\n",
    "a = confusion_matrix(y_test , yhat)\n",
    "print(a)\n",
    "print((a[0][0]+a[1][1])/(a[0][0]+a[0][1]+a[1][0]+a[1][1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CASE 4 :- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (160, 5) (160,)\n",
      "Test set: (40, 5) (40,)\n",
      "[[22  3]\n",
      " [11  4]]\n",
      "0.65\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df=pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%203/data/ChurnData.csv\")\n",
    "\n",
    "\n",
    "dff = df[[\"lninc\",\"custcat\",\"tenure\",\"confer\",\"ebill\"]]\n",
    "dff.head()\n",
    "\n",
    "X = np.asanyarray(dff[[\"lninc\",\"custcat\",\"tenure\",\"confer\",\"ebill\"]])\n",
    "\n",
    "y = np.asanyarray(df[\"churn\"])\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test , y_train , y_test = train_test_split(X,y,test_size = 0.2, random_state = 4)\n",
    "\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "LR = LogisticRegression(C = 0.01 , solver = 'liblinear').fit(X_train,y_train)\n",
    "LR\n",
    "\n",
    "yhat = LR.predict(X_test)\n",
    "yhat\n",
    "\n",
    "yhat_prob = LR.predict_proba(X_test)\n",
    "yhat_prob\n",
    "\n",
    "a = confusion_matrix(y_test , yhat)\n",
    "print(a)\n",
    "print((a[0][0]+a[1][1])/(a[0][0]+a[0][1]+a[1][0]+a[1][1]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CASE 5 :- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (160, 5) (160,)\n",
      "Test set: (40, 5) (40,)\n",
      "[[25  0]\n",
      " [11  4]]\n",
      "0.725\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df=pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%203/data/ChurnData.csv\")\n",
    "\n",
    "\n",
    "dff = df[[\"callcard\",\"income\",\"internet\",\"longmon\",\"custcat\"]]\n",
    "dff.head()\n",
    "\n",
    "X = np.asanyarray(dff[[\"callcard\",\"income\",\"internet\",\"longmon\",\"custcat\"]])\n",
    "\n",
    "y = np.asanyarray(df[\"churn\"])\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test , y_train , y_test = train_test_split(X,y,test_size = 0.2, random_state = 4)\n",
    "\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "LR = LogisticRegression(C = 0.01 , solver = 'liblinear').fit(X_train,y_train)\n",
    "LR\n",
    "\n",
    "yhat = LR.predict(X_test)\n",
    "yhat\n",
    "\n",
    "yhat_prob = LR.predict_proba(X_test)\n",
    "yhat_prob\n",
    "\n",
    "a = confusion_matrix(y_test , yhat)\n",
    "print(a)\n",
    "print((a[0][0]+a[1][1])/(a[0][0]+a[0][1]+a[1][0]+a[1][1]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So i tested most of the cases and according to my predictions the most accuracy achieved is 77.5% when we consider age, employ , longmon , loglong and logtoll as our feature sets"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
